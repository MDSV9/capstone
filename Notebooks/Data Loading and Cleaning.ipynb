{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246c5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data handling and simple visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Fancy progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setting pandas to display all necessary columns\n",
    "pd.set_option(\"display.max_columns\", 87)\n",
    "pd.set_option(\"display.max_rows\", 87)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffda25",
   "metadata": {},
   "source": [
    "# Capstone:  Data Loading, and Data Cleaning\n",
    "\n",
    "1. [Data Loading](#Data-loading)\n",
    "    - [Collecting Data](#Collecting-Data)\n",
    "    - [Loading Data](#Loading-and-Merging)\n",
    "2. [Data Cleaning](#Data-cleaning)\n",
    "    - [Transforming Dtypes](#Transforming-dtypes)\n",
    "    - [NaN Values and Outliers](#NaN-Values-and-Outliers)\n",
    "    - [Droping Features](#Droping-features)\n",
    "3. [Exporting](#Exporting-Clean-Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c6ab7",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "### Collecting Data\n",
    "\n",
    "The dataset we will be working with was synthetically created by the *Canadian Institute for Cybersecurity* (CIC). Initially, the dataset, known as [CIC-IDS2017](https://www.unb.ca/cic/datasets/ids-2017.html), comprises PCAP (Packet Capture) files obtained using the [CICFlowMeter](https://github.com/ahlashkari/CICFlowMeter) tool. These PCAP files were subsequently converted into `.csv` files using the same tool.\n",
    "\n",
    "The original dataset, however, contains various errors that may impact the predictions of traditional machine learning algorithms. Such errors include mislabeling of benign and malicious packets, as well as duplication of connections from the network. To address this, a French research team led by Maxime Lanvin developed a [cleaner version](https://hal.science/hal-03775466) of the dataset for CRiSIS 2022 (The 17th International Conference on Risks and Security of Internet and Systems). This capstone project is built upon this refined dataset, which we will further enhance and manipulate to create a machine learning model capable of detecting network intrusions.\n",
    "\n",
    "Throughout this capstone project, our goal is to refine the dataset, perform insightful data manipulation, and develop a powerful machine learning model that can effectively identify network intrusions. By leveraging this refined dataset, we aim to contribute to the advancement of cybersecurity and enhance network security measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a007f",
   "metadata": {},
   "source": [
    "### Loading and Merging\n",
    "\n",
    "To kickstart our data preparation process, the first step involves merging the dataset created by Maxime Lanvin and his team into a comprehensive `.csv` file. This merging enables us to efficiently handle NaN (null) values and outliers, ensuring the dataset's cleanliness and integrity. The following section outlines the process of merging the datasets, setting the stage for subsequent data cleaning procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0226976b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and Merging: 100%|████████████████████████████████████████████████████████████████| 5/5 [00:19<00:00,  3.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the merged data\n",
    "raw_data = pd.DataFrame()\n",
    "\n",
    "# Create an array of file paths to be loaded\n",
    "files = np.array(['data/Monday-WorkingHours.csv', 'data/Tuesday-WorkingHours.csv', 'data/Wednesday-WorkingHours.csv', 'data/Thursday-WorkingHours.csv', 'data/Friday-WorkingHours.csv'])\n",
    "\n",
    "for file in tqdm(files, desc='Loading and Merging'):\n",
    "    temp = pd.read_csv(file)\n",
    "    raw_data = pd.concat([raw_data, temp])\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c84b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2096448 entries, 0 to 548827\n",
      "Columns: 87 entries, Flow ID to Label\n",
      "dtypes: float64(45), int64(37), object(5)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "raw_data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796e2390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset contains 2096448 rows and 87 columns\n"
     ]
    }
   ],
   "source": [
    "print(f'Our dataset contains {raw_data.shape[0]} rows and {raw_data.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63090ba4",
   "metadata": {},
   "source": [
    "Upon analyzing our dataset, we observe a total of **2,096,448** data entries, representing individual packets from the original PCAP files. These packets are described by **87** features. The substantial size of this dataset amounts to approximately **1.4 GB** of storage. The large data volume is a result of the extensive number of data points and the storage format used. To optimize our dataset's manageability and prevent potential kernel crashes, we should inspect the maximum and minimum values. If these values fall within the range that an *int32* or *float32* can handle, we can efficiently convert them into these data types, significantly reducing the dataset's overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0867a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Src Port               False\n",
       "Dst Port               False\n",
       "Protocol               False\n",
       "Flow Duration          False\n",
       "Total Fwd Packet       False\n",
       "Total Bwd packets      False\n",
       "Fwd PSH Flags          False\n",
       "Bwd PSH Flags          False\n",
       "Fwd URG Flags          False\n",
       "Bwd URG Flags          False\n",
       "Fwd RST Flags          False\n",
       "Bwd RST Flags          False\n",
       "Fwd Header Length      False\n",
       "Bwd Header Length      False\n",
       "FIN Flag Count         False\n",
       "SYN Flag Count         False\n",
       "RST Flag Count         False\n",
       "PSH Flag Count         False\n",
       "ACK Flag Count         False\n",
       "URG Flag Count         False\n",
       "CWR Flag Count         False\n",
       "ECE Flag Count         False\n",
       "Fwd Bytes/Bulk Avg     False\n",
       "Fwd Packet/Bulk Avg    False\n",
       "Fwd Bulk Rate Avg      False\n",
       "Bwd Bytes/Bulk Avg     False\n",
       "Bwd Packet/Bulk Avg    False\n",
       "Bwd Bulk Rate Avg      False\n",
       "Subflow Fwd Packets    False\n",
       "Subflow Fwd Bytes      False\n",
       "Subflow Bwd Packets    False\n",
       "Subflow Bwd Bytes      False\n",
       "FWD Init Win Bytes     False\n",
       "Bwd Init Win Bytes     False\n",
       "Fwd Act Data Pkts      False\n",
       "Fwd Seg Size Min       False\n",
       "Total TCP Flow Time     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking only at int data that may exceed the int32 maximum\n",
    "raw_data.select_dtypes(include=[int]).max() > np.iinfo(np.int32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008e821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `Total TCP Flow Time` feature exceeds the int32 limit 3214 times\n"
     ]
    }
   ],
   "source": [
    "# Further testing to check the behavior of the Total TCP Flow Time column\n",
    "count = 0\n",
    "for val in raw_data['Total TCP Flow Time'].values:\n",
    "    if val > np.iinfo(np.int32).max:\n",
    "        count = count + 1\n",
    "print(f'The `Total TCP Flow Time` feature exceeds the int32 limit {count} times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0177f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.096448e+06\n",
       "mean     3.260285e+07\n",
       "std      3.932272e+08\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      1.500000e+01\n",
       "75%      3.317919e+06\n",
       "max      3.029044e+10\n",
       "Name: Total TCP Flow Time, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['Total TCP Flow Time'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec929ae",
   "metadata": {},
   "source": [
    "Based on our exploration, we've observed that among our integer features, only the `Total TCP Flow Time` column surpasses the maximum value of *int32*. Further investigation revealed that the 75th percentile of the `Total TCP Flow Time` column also exceeds the *int32* maximum, making it unsuitable for transformation without potential data loss.\n",
    "\n",
    "However, the good news is that the remaining integer features are highly eligible for conversion into a more memory-efficient data type. By optimizing these columns, we can significantly reduce the dataset's memory footprint while preserving data integrity and analytical accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19688ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Length of Fwd Packet    False\n",
       "Total Length of Bwd Packet    False\n",
       "Fwd Packet Length Max         False\n",
       "Fwd Packet Length Min         False\n",
       "Fwd Packet Length Mean        False\n",
       "Fwd Packet Length Std         False\n",
       "Bwd Packet Length Max         False\n",
       "Bwd Packet Length Min         False\n",
       "Bwd Packet Length Mean        False\n",
       "Bwd Packet Length Std         False\n",
       "Flow Bytes/s                   True\n",
       "Flow Packets/s                 True\n",
       "Flow IAT Mean                 False\n",
       "Flow IAT Std                  False\n",
       "Flow IAT Max                  False\n",
       "Flow IAT Min                  False\n",
       "Fwd IAT Total                 False\n",
       "Fwd IAT Mean                  False\n",
       "Fwd IAT Std                   False\n",
       "Fwd IAT Max                   False\n",
       "Fwd IAT Min                   False\n",
       "Bwd IAT Total                 False\n",
       "Bwd IAT Mean                  False\n",
       "Bwd IAT Std                   False\n",
       "Bwd IAT Max                   False\n",
       "Bwd IAT Min                   False\n",
       "Fwd Packets/s                 False\n",
       "Bwd Packets/s                 False\n",
       "Packet Length Min             False\n",
       "Packet Length Max             False\n",
       "Packet Length Mean            False\n",
       "Packet Length Std             False\n",
       "Packet Length Variance        False\n",
       "Down/Up Ratio                 False\n",
       "Average Packet Size           False\n",
       "Fwd Segment Size Avg          False\n",
       "Bwd Segment Size Avg          False\n",
       "Active Mean                   False\n",
       "Active Std                    False\n",
       "Active Max                    False\n",
       "Active Min                    False\n",
       "Idle Mean                     False\n",
       "Idle Std                      False\n",
       "Idle Max                      False\n",
       "Idle Min                      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking only at float data that may exceed the float32 maximum\n",
    "raw_data.select_dtypes(include=[float]).max() > np.finfo(np.float32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bcd8226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <th>Flow Packets/s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.062297e+06</td>\n",
       "      <td>2.096448e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.710381e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.396960e+02</td>\n",
       "      <td>3.447839e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.022169e+03</td>\n",
       "      <td>6.268610e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.701318e+04</td>\n",
       "      <td>8.733624e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Bytes/s  Flow Packets/s\n",
       "count  2.062297e+06    2.096448e+06\n",
       "mean            inf             inf\n",
       "std             NaN             NaN\n",
       "min    0.000000e+00    1.710381e-02\n",
       "25%    1.396960e+02    3.447839e+00\n",
       "50%    3.022169e+03    6.268610e+01\n",
       "75%    6.701318e+04    8.733624e+03\n",
       "max             inf             inf"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[['Flow Bytes/s', 'Flow Packets/s']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49357ee7",
   "metadata": {},
   "source": [
    "Upon examining the float values in our dataset, we have identified the presence of outliers in the form of `inf`. After consulting the documentation from *CICFlowmeter-V4.0*, it becomes evident that these outliers stem from anomalies during the packet capture process. To maintain the integrity and reliability of our dataset, it is crucial to take appropriate action by eliminating these extreme data points.\n",
    "\n",
    "On a positive note, we found that all other floating-point features do not present any issues, making them suitable candidates for conversion to *float32*. By making this transformation, we can effectively reduce the memory load, optimizing our dataset for more efficient processing while retaining the necessary level of precision for our analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469c96d",
   "metadata": {},
   "source": [
    "---\n",
    "## Data cleaning\n",
    "\n",
    "Even with our leaner dataset, the conventional approach of creating a separate dataset for dtype conversions and value removal may not be feasible on our current machine. As a possible next step, we should consider utilizing a cluster to distribute the computational load effectively.\n",
    "\n",
    "By leveraging a cluster computing system, we can parallelize the data processing tasks, allowing multiple machines to work collaboratively on different portions of the dataset simultaneously. This approach significantly enhances the processing speed and efficiency, making it possible to handle large-scale data transformations and optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bac73",
   "metadata": {},
   "source": [
    "### Transforming dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34622757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the appropriate features into a more memory-friendly type\n",
    "integer = []\n",
    "f = []\n",
    "for i in raw_data.columns[:-1]:\n",
    "    if raw_data[i].dtype == \"int64\":\n",
    "        if i == 'Total TCP Flow Time':\n",
    "            continue\n",
    "        integer.append(i)\n",
    "    elif raw_data[i].dtype == \"object\":\n",
    "        pass\n",
    "    else: \n",
    "        f.append(i)\n",
    "\n",
    "raw_data[integer] = raw_data[integer].astype(\"int32\")\n",
    "raw_data[f] = raw_data[f].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b968cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2096448 entries, 0 to 548827\n",
      "Data columns (total 87 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   Flow ID                     object \n",
      " 1   Src IP                      object \n",
      " 2   Src Port                    int32  \n",
      " 3   Dst IP                      object \n",
      " 4   Dst Port                    int32  \n",
      " 5   Protocol                    int32  \n",
      " 6   Timestamp                   object \n",
      " 7   Flow Duration               int32  \n",
      " 8   Total Fwd Packet            int32  \n",
      " 9   Total Bwd packets           int32  \n",
      " 10  Total Length of Fwd Packet  float32\n",
      " 11  Total Length of Bwd Packet  float32\n",
      " 12  Fwd Packet Length Max       float32\n",
      " 13  Fwd Packet Length Min       float32\n",
      " 14  Fwd Packet Length Mean      float32\n",
      " 15  Fwd Packet Length Std       float32\n",
      " 16  Bwd Packet Length Max       float32\n",
      " 17  Bwd Packet Length Min       float32\n",
      " 18  Bwd Packet Length Mean      float32\n",
      " 19  Bwd Packet Length Std       float32\n",
      " 20  Flow Bytes/s                float32\n",
      " 21  Flow Packets/s              float32\n",
      " 22  Flow IAT Mean               float32\n",
      " 23  Flow IAT Std                float32\n",
      " 24  Flow IAT Max                float32\n",
      " 25  Flow IAT Min                float32\n",
      " 26  Fwd IAT Total               float32\n",
      " 27  Fwd IAT Mean                float32\n",
      " 28  Fwd IAT Std                 float32\n",
      " 29  Fwd IAT Max                 float32\n",
      " 30  Fwd IAT Min                 float32\n",
      " 31  Bwd IAT Total               float32\n",
      " 32  Bwd IAT Mean                float32\n",
      " 33  Bwd IAT Std                 float32\n",
      " 34  Bwd IAT Max                 float32\n",
      " 35  Bwd IAT Min                 float32\n",
      " 36  Fwd PSH Flags               int32  \n",
      " 37  Bwd PSH Flags               int32  \n",
      " 38  Fwd URG Flags               int32  \n",
      " 39  Bwd URG Flags               int32  \n",
      " 40  Fwd RST Flags               int32  \n",
      " 41  Bwd RST Flags               int32  \n",
      " 42  Fwd Header Length           int32  \n",
      " 43  Bwd Header Length           int32  \n",
      " 44  Fwd Packets/s               float32\n",
      " 45  Bwd Packets/s               float32\n",
      " 46  Packet Length Min           float32\n",
      " 47  Packet Length Max           float32\n",
      " 48  Packet Length Mean          float32\n",
      " 49  Packet Length Std           float32\n",
      " 50  Packet Length Variance      float32\n",
      " 51  FIN Flag Count              int32  \n",
      " 52  SYN Flag Count              int32  \n",
      " 53  RST Flag Count              int32  \n",
      " 54  PSH Flag Count              int32  \n",
      " 55  ACK Flag Count              int32  \n",
      " 56  URG Flag Count              int32  \n",
      " 57  CWR Flag Count              int32  \n",
      " 58  ECE Flag Count              int32  \n",
      " 59  Down/Up Ratio               float32\n",
      " 60  Average Packet Size         float32\n",
      " 61  Fwd Segment Size Avg        float32\n",
      " 62  Bwd Segment Size Avg        float32\n",
      " 63  Fwd Bytes/Bulk Avg          int32  \n",
      " 64  Fwd Packet/Bulk Avg         int32  \n",
      " 65  Fwd Bulk Rate Avg           int32  \n",
      " 66  Bwd Bytes/Bulk Avg          int32  \n",
      " 67  Bwd Packet/Bulk Avg         int32  \n",
      " 68  Bwd Bulk Rate Avg           int32  \n",
      " 69  Subflow Fwd Packets         int32  \n",
      " 70  Subflow Fwd Bytes           int32  \n",
      " 71  Subflow Bwd Packets         int32  \n",
      " 72  Subflow Bwd Bytes           int32  \n",
      " 73  FWD Init Win Bytes          int32  \n",
      " 74  Bwd Init Win Bytes          int32  \n",
      " 75  Fwd Act Data Pkts           int32  \n",
      " 76  Fwd Seg Size Min            int32  \n",
      " 77  Active Mean                 float32\n",
      " 78  Active Std                  float32\n",
      " 79  Active Max                  float32\n",
      " 80  Active Min                  float32\n",
      " 81  Idle Mean                   float32\n",
      " 82  Idle Std                    float32\n",
      " 83  Idle Max                    float32\n",
      " 84  Idle Min                    float32\n",
      " 85  Total TCP Flow Time         int64  \n",
      " 86  Label                       object \n",
      "dtypes: float32(45), int32(36), int64(1), object(5)\n",
      "memory usage: 759.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2a54f",
   "metadata": {},
   "source": [
    "Our efforts to optimize the dataset have yielded significant results, reducing the memory usage from 1.4 GB to just 780 MB. This substantial reduction provides us with enhanced flexibility in handling the data, empowering us to perform various analyses and operations more efficiently. With a leaner dataset, we can now navigate through the data more smoothly and explore deeper insights without encountering as many memory-related constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df05b9",
   "metadata": {},
   "source": [
    "### NaN Values and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3ee2b",
   "metadata": {},
   "source": [
    "With our leaner dataset at hand, we can now proceed with the implementation of more conventional cleaning techniques, focusing on addressing null and extreme values. As we've already identified outliers in the form of `inf`, our first step will involve removing these problematic rows. The documentation from the tool responsible for capturing the packets from the network indicates that these inf values resulted from recording errors. Therefore to avoid adding unreliable data for our model to learn from we should remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "effec27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow ID                           0\n",
       "Src IP                            0\n",
       "Src Port                          0\n",
       "Dst IP                            0\n",
       "Dst Port                          0\n",
       "Protocol                          0\n",
       "Timestamp                         0\n",
       "Flow Duration                     0\n",
       "Total Fwd Packet                  0\n",
       "Total Bwd packets                 0\n",
       "Total Length of Fwd Packet        0\n",
       "Total Length of Bwd Packet        0\n",
       "Fwd Packet Length Max             0\n",
       "Fwd Packet Length Min             0\n",
       "Fwd Packet Length Mean            0\n",
       "Fwd Packet Length Std             0\n",
       "Bwd Packet Length Max             0\n",
       "Bwd Packet Length Min             0\n",
       "Bwd Packet Length Mean            0\n",
       "Bwd Packet Length Std             0\n",
       "Flow Bytes/s                  34151\n",
       "Flow Packets/s                    0\n",
       "Flow IAT Mean                 42998\n",
       "Flow IAT Std                  42998\n",
       "Flow IAT Max                  42998\n",
       "Flow IAT Min                  42998\n",
       "Fwd IAT Total                     0\n",
       "Fwd IAT Mean                      0\n",
       "Fwd IAT Std                       0\n",
       "Fwd IAT Max                       0\n",
       "Fwd IAT Min                       0\n",
       "Bwd IAT Total                     0\n",
       "Bwd IAT Mean                      0\n",
       "Bwd IAT Std                       0\n",
       "Bwd IAT Max                       0\n",
       "Bwd IAT Min                       0\n",
       "Fwd PSH Flags                     0\n",
       "Bwd PSH Flags                     0\n",
       "Fwd URG Flags                     0\n",
       "Bwd URG Flags                     0\n",
       "Fwd RST Flags                     0\n",
       "Bwd RST Flags                     0\n",
       "Fwd Header Length                 0\n",
       "Bwd Header Length                 0\n",
       "Fwd Packets/s                     0\n",
       "Bwd Packets/s                     0\n",
       "Packet Length Min                 0\n",
       "Packet Length Max                 0\n",
       "Packet Length Mean                0\n",
       "Packet Length Std                 0\n",
       "Packet Length Variance            0\n",
       "FIN Flag Count                    0\n",
       "SYN Flag Count                    0\n",
       "RST Flag Count                    0\n",
       "PSH Flag Count                    0\n",
       "ACK Flag Count                    0\n",
       "URG Flag Count                    0\n",
       "CWR Flag Count                    0\n",
       "ECE Flag Count                    0\n",
       "Down/Up Ratio                     0\n",
       "Average Packet Size               0\n",
       "Fwd Segment Size Avg              0\n",
       "Bwd Segment Size Avg              0\n",
       "Fwd Bytes/Bulk Avg                0\n",
       "Fwd Packet/Bulk Avg               0\n",
       "Fwd Bulk Rate Avg                 0\n",
       "Bwd Bytes/Bulk Avg                0\n",
       "Bwd Packet/Bulk Avg               0\n",
       "Bwd Bulk Rate Avg                 0\n",
       "Subflow Fwd Packets               0\n",
       "Subflow Fwd Bytes                 0\n",
       "Subflow Bwd Packets               0\n",
       "Subflow Bwd Bytes                 0\n",
       "FWD Init Win Bytes                0\n",
       "Bwd Init Win Bytes                0\n",
       "Fwd Act Data Pkts                 0\n",
       "Fwd Seg Size Min                  0\n",
       "Active Mean                       0\n",
       "Active Std                        0\n",
       "Active Max                        0\n",
       "Active Min                        0\n",
       "Idle Mean                         0\n",
       "Idle Std                          0\n",
       "Idle Max                          0\n",
       "Idle Min                          0\n",
       "Total TCP Flow Time               0\n",
       "Label                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values before removing anything else\n",
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c28433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing infinity values from our data\n",
    "raw_data = raw_data[~raw_data.isin([np.inf, -np.inf]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d143da49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow ID                       0\n",
       "Src IP                        0\n",
       "Src Port                      0\n",
       "Dst IP                        0\n",
       "Dst Port                      0\n",
       "Protocol                      0\n",
       "Timestamp                     0\n",
       "Flow Duration                 0\n",
       "Total Fwd Packet              0\n",
       "Total Bwd packets             0\n",
       "Total Length of Fwd Packet    0\n",
       "Total Length of Bwd Packet    0\n",
       "Fwd Packet Length Max         0\n",
       "Fwd Packet Length Min         0\n",
       "Fwd Packet Length Mean        0\n",
       "Fwd Packet Length Std         0\n",
       "Bwd Packet Length Max         0\n",
       "Bwd Packet Length Min         0\n",
       "Bwd Packet Length Mean        0\n",
       "Bwd Packet Length Std         0\n",
       "Flow Bytes/s                  0\n",
       "Flow Packets/s                0\n",
       "Flow IAT Mean                 0\n",
       "Flow IAT Std                  0\n",
       "Flow IAT Max                  0\n",
       "Flow IAT Min                  0\n",
       "Fwd IAT Total                 0\n",
       "Fwd IAT Mean                  0\n",
       "Fwd IAT Std                   0\n",
       "Fwd IAT Max                   0\n",
       "Fwd IAT Min                   0\n",
       "Bwd IAT Total                 0\n",
       "Bwd IAT Mean                  0\n",
       "Bwd IAT Std                   0\n",
       "Bwd IAT Max                   0\n",
       "Bwd IAT Min                   0\n",
       "Fwd PSH Flags                 0\n",
       "Bwd PSH Flags                 0\n",
       "Fwd URG Flags                 0\n",
       "Bwd URG Flags                 0\n",
       "Fwd RST Flags                 0\n",
       "Bwd RST Flags                 0\n",
       "Fwd Header Length             0\n",
       "Bwd Header Length             0\n",
       "Fwd Packets/s                 0\n",
       "Bwd Packets/s                 0\n",
       "Packet Length Min             0\n",
       "Packet Length Max             0\n",
       "Packet Length Mean            0\n",
       "Packet Length Std             0\n",
       "Packet Length Variance        0\n",
       "FIN Flag Count                0\n",
       "SYN Flag Count                0\n",
       "RST Flag Count                0\n",
       "PSH Flag Count                0\n",
       "ACK Flag Count                0\n",
       "URG Flag Count                0\n",
       "CWR Flag Count                0\n",
       "ECE Flag Count                0\n",
       "Down/Up Ratio                 0\n",
       "Average Packet Size           0\n",
       "Fwd Segment Size Avg          0\n",
       "Bwd Segment Size Avg          0\n",
       "Fwd Bytes/Bulk Avg            0\n",
       "Fwd Packet/Bulk Avg           0\n",
       "Fwd Bulk Rate Avg             0\n",
       "Bwd Bytes/Bulk Avg            0\n",
       "Bwd Packet/Bulk Avg           0\n",
       "Bwd Bulk Rate Avg             0\n",
       "Subflow Fwd Packets           0\n",
       "Subflow Fwd Bytes             0\n",
       "Subflow Bwd Packets           0\n",
       "Subflow Bwd Bytes             0\n",
       "FWD Init Win Bytes            0\n",
       "Bwd Init Win Bytes            0\n",
       "Fwd Act Data Pkts             0\n",
       "Fwd Seg Size Min              0\n",
       "Active Mean                   0\n",
       "Active Std                    0\n",
       "Active Max                    0\n",
       "Active Min                    0\n",
       "Idle Mean                     0\n",
       "Idle Std                      0\n",
       "Idle Max                      0\n",
       "Idle Min                      0\n",
       "Total TCP Flow Time           0\n",
       "Label                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06753819",
   "metadata": {},
   "source": [
    "Fortunately, it appears that all of our null values align with the recording errors during the packet capture process. Consequently, by removing the rows containing inf values, we have successfully eliminated all the NaN (null) values from our dataset as well. This stroke of luck simplifies our data cleaning process, as we no longer need to handle separate cases for null values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0480923",
   "metadata": {},
   "source": [
    "### Droping features\n",
    "\n",
    "In the interest of refining our dataset to focus on relevant information for our model, we have decided to remove the following columns:\n",
    "\n",
    "1. **'Fwd URG Flags', 'Bwd URG Flags', 'URG Flag Count'**: These flags pertain to a deprecated protocol and are not useful for our model's analysis. Here is a [neat writeup](https://packetlife.net/blog/2011/mar/2/tcp-flags-psh-and-urg/) that explains more about URG Flags\n",
    "\n",
    "2. **'Flow ID', 'Src IP', 'Src Port', 'Dst IP'**: To ensure that the model focuses on discerning packet classifications and not machine-specific details, we will remove columns related to individual machine addresses.\n",
    "\n",
    "3. **'Timestamp'**: Likewise, we aim to guide the model in identifying attack patterns rather than associating them with specific timestamps, so we will exclude this column from our analysis.\n",
    "\n",
    "By eliminating these columns, we streamline our dataset to concentrate on essential features, enabling the model to better grasp the characteristics that differentiate benign and malignant packets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af367a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2053039, 87)\n"
     ]
    }
   ],
   "source": [
    "# Removing columns that may misguide our model or offer no important information\n",
    "drop_cols = ['Fwd URG Flags', 'Bwd URG Flags', 'URG Flag Count', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Timestamp']\n",
    "print(raw_data.shape)\n",
    "raw_data = raw_data.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97086f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2053039, 79)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3af6de",
   "metadata": {},
   "source": [
    "## Exporting Clean Data\n",
    "\n",
    "As the final step in our data cleanup process, we will proceed to export this clean dataset for further use in exploratory data analysis (EDA) and modeling. By exporting the cleaned data, we create a reliable and standardized foundation for subsequent analyses and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "947a2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a CSV file\n",
    "raw_data.to_csv('data/WorkWeek_CleanData.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a87b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing json to export the appropiate dtyes to avoid convertions on other notebooks\n",
    "import json\n",
    "# Create the dtypes dictionary from df.dtypes\n",
    "dtypes_dict = raw_data.dtypes.apply(lambda x: x.name).to_dict()\n",
    "\n",
    "# Save the dtypes to a JSON file using the json library\n",
    "with open('data/dtypes.json', 'w') as json_file:\n",
    "    json.dump(dtypes_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a390c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving the used memory space (somewhat unecessary)\n",
    "del raw_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
